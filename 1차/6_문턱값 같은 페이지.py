'''
ìŒ.. ì¼ë‹¨ ì•ˆì¢‹ì€ê±° ê°™ìŒ ë¹„êµí•˜ëŠ”ê±´ ì¢‹ì€ë°,,,
ê·¸ëƒ¥ í˜ì´ì§€ë¥¼ ë„˜ê¸°ë©´ í•œì¥ ì°ì—ˆìœ¼ë©´ ì¢‹ê² ë‹¤.
'''

import cv2
import numpy as np
from ultralytics import YOLO
import uuid
import os
import time
import requests
import base64
import json
from dotenv import load_dotenv
from difflib import SequenceMatcher

# ì±… ì œëª© ì„¤ì • (í…Œì´ë¸”/íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©ë¨)
book_title = "ë…¼ì–´"

# ğŸ” .envì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

def detect_text_rest(image_path):
    with open(image_path, "rb") as image_file:
        content = base64.b64encode(image_file.read()).decode("utf-8")

    url = f"https://vision.googleapis.com/v1/images:annotate?key={API_KEY}"

    payload = {
        "requests": [
            {
                "image": {"content": content},
                "features": [{"type": "TEXT_DETECTION"}],
            }
        ]
    }

    headers = {"Content-Type": "application/json"}
    response = requests.post(url, headers=headers, data=json.dumps(payload))
    result = response.json()

    try:
        description = result["responses"][0]["textAnnotations"][0]["description"]
        return description.strip()
    except (KeyError, IndexError):
        return ""

def is_different_page(text1, text2, threshold=0.5):
    ratio = SequenceMatcher(None, text1, text2).ratio()
    return ratio < threshold

def auto_detect_and_ocr(model_path="yolo11n.pt"):
    model = YOLO(model_path)
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        return

    save_dir = f"book_pages/{book_title}"
    os.makedirs(save_dir, exist_ok=True)

    text_file_path = f"{book_title}.txt"
    image_counter = 1
    prev_left_text = ""
    prev_right_text = ""
    last_capture_time = time.time()

    print(f"ğŸ“˜ ì±…: {book_title} | ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ì €ì¥ ì‹œì‘ (ESCë¡œ ì¢…ë£Œ)")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame, verbose=False)[0]

        book_box = None
        for box in results.boxes:
            if int(box.cls[0]) == 73:
                book_box = box
                break

        if book_box:
            x1, y1, x2, y2 = map(int, book_box.xyxy[0])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, "BOOK DETECTED - AUTO MODE", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            now = time.time()
            if now - last_capture_time >= 3:
                book_crop = frame[y1:y2, x1:x2]
                h, w, _ = book_crop.shape
                mid = w // 2
                left_page = book_crop[:, :mid]
                right_page = book_crop[:, mid:]

                # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
                temp_left_path = os.path.join(save_dir, "temp_left.jpg")
                temp_right_path = os.path.join(save_dir, "temp_right.jpg")
                cv2.imwrite(temp_left_path, left_page)
                cv2.imwrite(temp_right_path, right_page)

                left_text = detect_text_rest(temp_left_path)
                right_text = detect_text_rest(temp_right_path)

                if is_different_page(left_text, prev_left_text) or is_different_page(right_text, prev_right_text):
                    # ë²ˆí˜¸ ë¶™ì¸ íŒŒì¼ ì €ì¥
                    left_path = os.path.join(save_dir, f"{book_title}_left_{image_counter:03}.jpg")
                    right_path = os.path.join(save_dir, f"{book_title}_right_{image_counter:03}.jpg")
                    cv2.imwrite(left_path, left_page)
                    cv2.imwrite(right_path, right_page)

                    print(f"\nâœ… ìƒˆ í˜ì´ì§€ ì €ì¥ë¨:")
                    print(f"ğŸ“– ì™¼ìª½: {left_path}\n{left_text}")
                    print(f"\nğŸ“– ì˜¤ë¥¸ìª½: {right_path}\n{right_text}")

                    # í…ìŠ¤íŠ¸ ëˆ„ì  ì €ì¥
                    with open(text_file_path, "a", encoding="utf-8") as f:
                        f.write(f"\n--- ì™¼ìª½ í˜ì´ì§€ ({image_counter}) ---\n{left_text}\n")
                        f.write(f"\n--- ì˜¤ë¥¸ìª½ í˜ì´ì§€ ({image_counter}) ---\n{right_text}\n")

                    prev_left_text = left_text
                    prev_right_text = right_text
                    image_counter += 1
                else:
                    print("â© í˜ì´ì§€ ë™ì¼, ì €ì¥ ìƒëµ")

                last_capture_time = now

        cv2.imshow("Auto Book Scan", frame)
        if cv2.waitKey(1) & 0xFF == 27:
            break

    cap.release()
    cv2.destroyAllWindows()

# ì‹¤í–‰
auto_detect_and_ocr()
