import cv2
import numpy as np
from ultralytics import YOLO
import os
import time
import requests
import base64
import json
from dotenv import load_dotenv
from difflib import SequenceMatcher
import io
from PIL import Image
import speech_recognition as sr
from gtts import gTTS
import pygame
import threading
from pymongo import MongoClient

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB_NAME = os.getenv("MONGO_DB_NAME")
MONGO_COLLECTION_NAME = os.getenv("MONGO_COLLECTION_NAME")

# ğŸ“Œ ì „ì—­ í”Œë˜ê·¸
stop_flag = False

# ğŸ“¢ ìŒì„± ì¶œë ¥ (pygame ê¸°ë°˜)
def speak(text):
    try:
        tts = gTTS(text=text, lang="ko")
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)

        pygame.mixer.init()
        pygame.mixer.music.load(fp)
        pygame.mixer.music.play()

        while pygame.mixer.music.get_busy():
            continue

        pygame.mixer.quit()
    except Exception as e:
        print(f"âŒ TTS ì˜¤ë¥˜: {e}")

# ğŸ“Œ ì´ë¯¸ì§€ ì¸ì½”ë”©
def encode_image_cv2_to_base64(cv2_img):
    pil_img = Image.fromarray(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))
    buffer = io.BytesIO()
    pil_img.save(buffer, format="JPEG")
    return base64.b64encode(buffer.getvalue()).decode("utf-8")

# ğŸ“Œ Google OCR
def detect_text_from_array(cv2_img):
    content = encode_image_cv2_to_base64(cv2_img)
    url = f"https://vision.googleapis.com/v1/images:annotate?key={API_KEY}"
    payload = {
        "requests": [{
            "image": {"content": content},
            "features": [{"type": "TEXT_DETECTION"}]
        }]
    }
    headers = {"Content-Type": "application/json"}
    response = requests.post(url, headers=headers, data=json.dumps(payload))
    result = response.json()
    try:
        return result["responses"][0]["textAnnotations"][0]["description"].strip()
    except (KeyError, IndexError):
        return ""

# ğŸ“Œ ìœ ì‚¬ë„ ë¹„êµ
def is_different_page(text1, text2, threshold=0.5):
    ratio = SequenceMatcher(None, text1, text2).ratio()
    return ratio < threshold

def wait_for_voice_trigger_and_get_title():
    recognizer = sr.Recognizer()
    print("ğŸ¤ 'ì”¨í' ë¼ê³  ë§í•˜ë©´ ì‹œì‘í•©ë‹ˆë‹¤... (ë˜ëŠ” 'ê·¸ë§Œ' ì´ë¼ê³  ë§í•˜ë©´ ì¢…ë£Œ)")

    while True:
        try:
            with sr.Microphone() as source:
                recognizer.adjust_for_ambient_noise(source, duration=1)
                print("ğŸ§ ì‹œë™ì–´ ë“£ëŠ” ì¤‘...")
                audio = recognizer.listen(source)
                command = recognizer.recognize_google(audio, language="ko-KR")
                
                # ë‚´ë¶€ ì¸ì‹ ê²°ê³¼ëŠ” ë¡œê·¸ì—ì„œ ìˆ¨ê¹€
                # print("ğŸ“ ì¸ì‹ëœ ë‚´ìš©:", command)

                if "ê·¸ë§Œ" in command:
                    speak("ì¢…ë£Œí• ê²Œìš”.")
                    print("ğŸ›‘ ìŒì„±ìœ¼ë¡œ 'ê·¸ë§Œ' ê°ì§€ë¨ â†’ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
                    return None

                if (
                    "ì”¨í" in command 
                    or "ì‹œí" in command 
                    or "cq" in command.lower() 
                    or "thank you" in command.lower()
                ):
                    print("âœ… ì‹œë™ì–´ ì¸ì‹ë¨: ì”¨í")
                    speak("ì±… ì œëª©ì„ ë§ì”€í•´ì£¼ì„¸ìš”.")
                    while True:
                        try:
                            with sr.Microphone() as source:
                                recognizer.adjust_for_ambient_noise(source, duration=1)
                                audio = recognizer.listen(source)
                                title = recognizer.recognize_google(audio, language="ko-KR")
                                print("ğŸ“š ì¸ì‹ëœ ì±… ì œëª©:", title)
                                return title.strip()
                        except sr.UnknownValueError:
                            print("âŒ ì±… ì œëª© ì¸ì‹ ì‹¤íŒ¨. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
                            speak("ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
                        except sr.RequestError as e:
                            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {e}")
                            break
                else:
                    print("ğŸ” ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš” ('ì”¨í' ë˜ëŠ” 'ì‹œí')")
        except (sr.UnknownValueError, sr.RequestError) as e:
            print(f"âŒ ì‹œë™ì–´ ì¸ì‹ ì˜¤ë¥˜: {e}")
            continue
        except Exception as e:
            print(f"âŒ ë§ˆì´í¬ ì˜¤ë¥˜: {e}")
            continue

# ğŸ“Œ 'ì½ì–´' 'ê·¸ë§Œ' ê°ì§€ ìŠ¤ë ˆë“œ (ë””ë²„ê·¸ ìµœì†Œ, í•µì‹¬ ì´ë²¤íŠ¸ë§Œ ì¶œë ¥)
def listen_for_stop_word(get_last_text_func):
    global stop_flag
    recognizer = sr.Recognizer()

    while not stop_flag:
        try:
            with sr.Microphone() as source:
                recognizer.adjust_for_ambient_noise(source, duration=1)
                audio = recognizer.listen(source)
                command = recognizer.recognize_google(audio, language="ko-KR")

                if "ê·¸ë§Œ" in command:
                    stop_flag = True
                    speak("ì¤‘ë‹¨í• ê²Œìš”.")
                    print("ğŸ›‘ 'ê·¸ë§Œ' ê°ì§€ë¨ â†’ OCR ì¤‘ë‹¨")
                elif "ì½ì–´" in command:
                    print("ğŸ”Š 'ì½ì–´' ê°ì§€ë¨ â†’ í˜ì´ì§€ ì½ê¸°")
                    left, right = get_last_text_func()
                    speak(f"ì™¼ìª½ í˜ì´ì§€ì…ë‹ˆë‹¤. {left}")
                    speak(f"ì˜¤ë¥¸ìª½ í˜ì´ì§€ì…ë‹ˆë‹¤. {right}")
                # elseëŠ” ì•„ë¬´ ì¶œë ¥ ì—†ì´ ë„˜ì–´ê°
        except sr.WaitTimeoutError:
            pass  # íƒ€ì„ì•„ì›ƒ â†’ ë¬´ì‹œ
        except sr.UnknownValueError:
            pass  # ì¸ì‹ ì‹¤íŒ¨ â†’ ë¬´ì‹œ
        except sr.RequestError:
            break  # ìš”ì²­ ì˜¤ë¥˜ â†’ ì¢…ë£Œ


# ğŸ“Œ OCR ë©”ì¸ ë£¨í”„
def auto_detect_and_ocr_with_stop(book_title, model_path="yolo11n.pt"):
    global stop_flag
    stop_flag = False

    last_left_text = ""
    last_right_text = ""

    def get_last_text():
        return last_left_text, last_right_text

    threading.Thread(target=listen_for_stop_word, args=(get_last_text,), daemon=True).start()

    model = YOLO(model_path)
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        return

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3840)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)

    base_dir = f"book_pages/{book_title}"
    os.makedirs(os.path.join(base_dir, "left"), exist_ok=True)
    os.makedirs(os.path.join(base_dir, "right"), exist_ok=True)
    text_file_path = os.path.join(base_dir, f"{book_title}.txt")

    image_counter = 1
    prev_left_text = ""
    prev_right_text = ""
    book_detected_time = None
    skip_until_time = 0
    preview_size = (960, 540)
    all_texts = []

    print(f"ğŸ“˜ ì±…: {book_title} | OCR ì‹œì‘ (ESC ë˜ëŠ” 'ê·¸ë§Œ'ìœ¼ë¡œ ì¢…ë£Œ)")

    while not stop_flag:
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame, verbose=False)[0]
        book_box = None
        for box in results.boxes:
            if int(box.cls[0]) == 73:
                book_box = box
                break

        if book_box:
            x1, y1, x2, y2 = map(int, book_box.xyxy[0])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, "BOOK DETECTED", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            now = time.time()
            if book_detected_time is None:
                book_detected_time = now

            if now - book_detected_time >= 5 and now >= skip_until_time:
                book_crop = frame[y1:y2, x1:x2]
                h, w, _ = book_crop.shape
                mid = w // 2
                left_page = book_crop[:, :mid]
                right_page = book_crop[:, mid:]

                left_text = detect_text_from_array(left_page)
                right_text = detect_text_from_array(right_page)

                if len(left_text.strip()) < 30 and len(right_text.strip()) < 30:
                    print("âŒ ê¸€ì ìˆ˜ ë¶€ì¡± - ì €ì¥ ìƒëµ")
                    skip_until_time = now + 5
                    continue

                if is_different_page(left_text, prev_left_text) or is_different_page(right_text, prev_right_text):
                    left_img_path = os.path.join(base_dir, "left", f"page_{image_counter}_left.jpg")
                    right_img_path = os.path.join(base_dir, "right", f"page_{image_counter}_right.jpg")
                    cv2.imwrite(left_img_path, left_page)
                    cv2.imwrite(right_img_path, right_page)

                    with open(text_file_path, "a", encoding="utf-8") as f:
                        f.write(left_text + "\n")
                        f.write(right_text + "\n")

                    all_texts.append(left_text)
                    all_texts.append(right_text)

                    last_left_text = left_text
                    last_right_text = right_text

                    print(f"âœ… í˜ì´ì§€ {image_counter} ì €ì¥ ì™„ë£Œ")
                    prev_left_text = left_text
                    prev_right_text = right_text
                    image_counter += 1
                    book_detected_time = None
                    skip_until_time = 0
                else:
                    print("â© ì¤‘ë³µ í˜ì´ì§€ - 3ì´ˆ í›„ ì¬ì‹œë„")
                    skip_until_time = now + 5
        else:
            book_detected_time = None
            skip_until_time = 0

        preview_frame = cv2.resize(frame, preview_size)
        cv2.imshow("Auto Book Scan", preview_frame)

        if cv2.waitKey(1) & 0xFF == 27:
            print("ğŸ›‘ ESC ëˆŒë¦¼ â†’ OCR ì¤‘ë‹¨")
            stop_flag = True
            break

    cap.release()
    cv2.destroyAllWindows()

    # ğŸ“¦ MongoDBì— ì €ì¥
    if all_texts:
        try:
            client = MongoClient(MONGO_URI)
            db = client[MONGO_DB_NAME]
            collection = db[MONGO_COLLECTION_NAME]
            doc = {
                "title": book_title,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "pages": all_texts
            }
            collection.insert_one(doc)
            print(f"âœ… MongoDBì— '{book_title}' ì „ì²´ í˜ì´ì§€ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ MongoDB ì „ì†¡ ì‹¤íŒ¨: {e}")

    return True

# ğŸ“Œ ë©”ì¸ ë£¨í”„
if __name__ == "__main__":
    while True:
        book_title = wait_for_voice_trigger_and_get_title()
        if book_title is None:
            break
        auto_detect_and_ocr_with_stop(book_title)
