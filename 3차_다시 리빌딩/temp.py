import cv2
import numpy as np
from ultralytics import YOLO
import os
import time
import requests
import base64
import json
from dotenv import load_dotenv
from difflib import SequenceMatcher
import io
from PIL import Image, ImageFont, ImageDraw
from gtts import gTTS
import pygame
import threading
from pymongo import MongoClient

# üîê ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB_NAME = os.getenv("MONGO_DB_NAME")
MONGO_COLLECTION_NAME = os.getenv("MONGO_COLLECTION_NAME")

stop_flag = False

# ‚úÖ ÌïúÍ∏Ä ÏûêÎßâ Ï∂úÎ†•
def put_korean_text(cv2_img, text, position=(50, 60), font_size=32, color=(255, 255, 255)):
    img_pil = Image.fromarray(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    font_path = "C:/Windows/Fonts/malgun.ttf"  # ÌôòÍ≤ΩÏóê ÎßûÍ≤å Í≤ΩÎ°ú Ï°∞Ï†ï
    font = ImageFont.truetype(font_path, font_size)
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ‚úÖ TTS
def speak(text):
    try:
        tts = gTTS(text=text, lang="ko")
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        pygame.mixer.init()
        pygame.mixer.music.load(fp)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            continue
        pygame.mixer.quit()
    except:
        pass

# ‚úÖ OCR
def encode_image_cv2_to_base64(cv2_img):
    pil_img = Image.fromarray(cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB))
    buffer = io.BytesIO()
    pil_img.save(buffer, format="JPEG")
    return base64.b64encode(buffer.getvalue()).decode("utf-8")

def detect_text_from_array(cv2_img):
    content = encode_image_cv2_to_base64(cv2_img)
    url = f"https://vision.googleapis.com/v1/images:annotate?key={API_KEY}"
    payload = {
        "requests": [{
            "image": {"content": content},
            "features": [{"type": "TEXT_DETECTION"}]
        }]
    }
    headers = {"Content-Type": "application/json"}
    response = requests.post(url, headers=headers, data=json.dumps(payload))
    result = response.json()
    try:
        return result["responses"][0]["textAnnotations"][0]["description"].strip()
    except:
        return ""

def is_different_page(text1, text2, threshold=0.5):
    ratio = SequenceMatcher(None, text1, text2).ratio()
    return ratio < threshold

# ‚úÖ ÌÇ§Î≥¥Îìú Î™ÖÎ†πÏñ¥ Ï≤òÎ¶¨ Ïì∞Î†àÎìú
def listen_keyboard(get_last_text_func):
    global stop_flag
    while not stop_flag:
        command = input("üëâ Î™ÖÎ†π ÏûÖÎ†• (ÏùΩÏñ¥ / Í∑∏Îßå): ").strip()
        if command == "Í∑∏Îßå":
            stop_flag = True
            speak("Ï§ëÎã®Ìï†Í≤åÏöî.")
        elif command == "ÏùΩÏñ¥":
            left, right = get_last_text_func()
            speak(f"ÏôºÏ™Ω ÌéòÏù¥ÏßÄÏûÖÎãàÎã§. {left}")
            speak(f"Ïò§Î•∏Ï™Ω ÌéòÏù¥ÏßÄÏûÖÎãàÎã§. {right}")
        else:
            print("‚ö†Ô∏è ÏßÄÏõêÎêòÏßÄ ÏïäÎäî Î™ÖÎ†πÏûÖÎãàÎã§.")

# ‚úÖ Î©îÏù∏ Î£®ÌîÑ
def auto_detect_and_ocr_with_stop(book_title, model_path="yolo11n.pt"):
    global stop_flag
    stop_flag = False

    last_left_text = ""
    last_right_text = ""

    def get_last_text():
        return last_left_text, last_right_text

    threading.Thread(target=listen_keyboard, args=(get_last_text,), daemon=True).start()

    model = YOLO(model_path)
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("‚ùå ÏõπÏ∫† Ïó¥Í∏∞ Ïã§Ìå®")
        return

    FRAME_WIDTH, FRAME_HEIGHT = 1920, 1080
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(f"{book_title}_ÎÖπÌôîÎ≥∏.mp4", fourcc, 10.0, (FRAME_WIDTH, FRAME_HEIGHT))

    base_dir = f"book_pages/{book_title}"
    os.makedirs(os.path.join(base_dir, "left"), exist_ok=True)
    os.makedirs(os.path.join(base_dir, "right"), exist_ok=True)
    text_file_path = os.path.join(base_dir, f"{book_title}.txt")

    image_counter = 1
    prev_left_text = ""
    prev_right_text = ""
    book_detected_time = None
    skip_until_time = 0
    preview_size = (960, 540)
    all_texts = []
    status_message = ""
    status_time = 0

    print(f"üìò Ï±Ö: {book_title} | OCR ÏãúÏûë")

    while not stop_flag:
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame, verbose=False)[0]
        book_box = None
        for box in results.boxes:
            if int(box.cls[0]) == 73:
                book_box = box
                break

        now = time.time()

        if book_box:
            x1, y1, x2, y2 = map(int, book_box.xyxy[0])
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, "BOOK DETECTED", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            if book_detected_time is None:
                book_detected_time = now

            if now - book_detected_time >= 5 and now >= skip_until_time:
                book_crop = frame[y1:y2, x1:x2]
                h, w, _ = book_crop.shape
                mid = w // 2
                left_page = book_crop[:, :mid]
                right_page = book_crop[:, mid:]

                left_text = detect_text_from_array(left_page)
                right_text = detect_text_from_array(right_page)

                if len(left_text.strip()) < 30 and len(right_text.strip()) < 30:
                    status_message = "‚ùå Í∏ÄÏûê Ïàò Î∂ÄÏ°± - ÏÉùÎûµ"
                    status_time = now
                    skip_until_time = now + 5
                    continue

                if is_different_page(left_text, prev_left_text) or is_different_page(right_text, prev_right_text):
                    lpath = os.path.join(base_dir, "left", f"page_{image_counter}_left.jpg")
                    rpath = os.path.join(base_dir, "right", f"page_{image_counter}_right.jpg")
                    cv2.imwrite(lpath, left_page)
                    cv2.imwrite(rpath, right_page)

                    with open(text_file_path, "a", encoding="utf-8") as f:
                        f.write(left_text + "\n" + right_text + "\n")

                    all_texts.append(left_text)
                    all_texts.append(right_text)
                    last_left_text = left_text
                    last_right_text = right_text
                    status_message = f"‚úÖ ÌéòÏù¥ÏßÄ {image_counter} Ï†ÄÏû•Îê®"
                    status_time = now
                    prev_left_text = left_text
                    prev_right_text = right_text
                    image_counter += 1
                    book_detected_time = None
                    skip_until_time = 0
                else:
                    status_message = "‚è© Ï§ëÎ≥µ ÌéòÏù¥ÏßÄ ÏÉùÎûµ"
                    status_time = now
                    skip_until_time = now + 5
        else:
            book_detected_time = None
            skip_until_time = 0

        # ‚úÖ ÏûêÎßâ Í∑∏Î¶¨Í∏∞
        if time.time() - status_time <= 2 and status_message:
            frame = put_korean_text(frame, status_message, font_size=42, position=(60, 60))

        # ‚úÖ ÏµúÏ¢Ö ÌîÑÎ†àÏûÑ ÎÖπÌôî
        video_writer.write(frame)

        # ‚úÖ ÌîÑÎ¶¨Î∑∞
        preview_frame = cv2.resize(frame, preview_size)
        cv2.imshow("Auto Book Scan", preview_frame)

        if cv2.waitKey(1) & 0xFF == 27:
            stop_flag = True
            break

    cap.release()
    video_writer.release()
    cv2.destroyAllWindows()

    if all_texts:
        try:
            client = MongoClient(MONGO_URI)
            db = client[MONGO_DB_NAME]
            collection = db[MONGO_COLLECTION_NAME]
            doc = {
                "title": book_title,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "pages": all_texts
            }
            collection.insert_one(doc)
            print(f"‚úÖ MongoDBÏóê '{book_title}' Ï†ÄÏû• ÏôÑÎ£å")
        except Exception as e:
            print(f"‚ùå MongoDB Ï†ÄÏû• Ïã§Ìå®: {e}")

    return True

# ‚úÖ Î©îÏù∏ Î£®ÌîÑ
if __name__ == "__main__":
    title = input("üìò Ï±Ö Ï†úÎ™©ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî: ").strip()
    if title:
        auto_detect_and_ocr_with_stop(title)
